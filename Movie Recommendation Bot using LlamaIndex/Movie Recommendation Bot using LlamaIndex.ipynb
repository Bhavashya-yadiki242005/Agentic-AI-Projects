{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip4Bzw5oekJk",
        "outputId": "7e265cc4-c2ef-45ca-e7dd-20fd53a67d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CPU for LLM.\n",
            "Welcome to MovieRecBot! \n",
            "How can I assist you in finding your next movie to watch? (Type 'exit' to end)\n",
            "Processing your movie recommendation...\n",
            "\n",
            "MovieRecs Assistant:\n",
            "- Schindler's List\n",
            "- Schindler's List\n",
            "- Schindler's List\n",
            "- Schindler's List\n",
            "- Explanation:\n",
            "Processing your movie recommendation...\n",
            "\n",
            "MovieRecs Assistant:\n",
            "- Schindler's List\n",
            "- The Matrix\n",
            "- Recommendations:\n",
            "- 1. Schindler's List\n",
            "- 2. The Matrix\n"
          ]
        }
      ],
      "source": [
        "# !pip install --upgrade llama-index llama-index-embeddings-huggingface llama-index-llms-huggingface transformers torch accelerate bitsandbytes\n",
        "\n",
        "import pandas as pd\n",
        "from llama_index.core import Settings, VectorStoreIndex, Document\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "import torch\n",
        "import os\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "\n",
        "    model_kwargs = {\"torch_dtype\": torch.float16, \"load_in_4bit\": True}\n",
        "    device_map = \"auto\"\n",
        "    print(\"Using CUDA device for LLM.\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    model_kwargs = {\"torch_dtype\": torch.float32}\n",
        "    device_map = \"cpu\"\n",
        "    if \"load_in_4bit\" in model_kwargs:\n",
        "        del model_kwargs[\"load_in_4bit\"]\n",
        "    print(\"Using CPU for LLM.\")\n",
        "\n",
        "\n",
        "Settings.llm = HuggingFaceLLM(\n",
        "    model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    tokenizer_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    context_window=2048,\n",
        "    max_new_tokens=256,\n",
        "    device_map=device_map,\n",
        "    model_kwargs=model_kwargs\n",
        ")\n",
        "\n",
        "csv_file_path = \"YOUR_CSV_FILE'S_PATH\"\n",
        "df = None\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: CSV file not found at {csv_file_path}\")\n",
        "    print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred while reading the CSV: {e}\")\n",
        "\n",
        "if df is not None:\n",
        "    movies_data = [\n",
        "        Document(text=f\"MovieID: {row['movie_id']}, Title: {row['title']}, Genre: {row['genre']}, Rating: {row['rating']}\",\n",
        "                 metadata={\"movie_id\": row['movie_id'], \"title\": row['title'], \"genre\": row['genre'], \"rating\": row['rating']})\n",
        "        for index, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    index = VectorStoreIndex.from_documents(movies_data)\n",
        "\n",
        "    query_engine = index.as_query_engine()\n",
        "\n",
        "    print(\"Welcome to MovieRecBot! \")\n",
        "    print(\"How can I assist you in finding your next movie to watch? (Type 'exit' to end)\")\n",
        "\n",
        "    while True:\n",
        "        query_string = input(\"\\nWhat type of movie are you in the mood for?\\n \")\n",
        "        if query_string.lower() == 'exit':\n",
        "            print(\"Thank you for using MovieRecs! Enjoy your movie and have a great day!\\n\")\n",
        "            break\n",
        "        print(\"Processing your movie recommendation...\")\n",
        "\n",
        "        response = query_engine.query(f\"List titles and genres of movies with the genre {query_string} from the provided data. Provide at least 3 recommendations if available.\")\n",
        "\n",
        "        response_lines = str(response).split('\\n')\n",
        "\n",
        "        filtered_recommendations = [\n",
        "            line for line in response_lines\n",
        "            if line.strip() and \"Note: The query is not specific to the data provided\" not in line\n",
        "        ]\n",
        "\n",
        "        formatted_recommendations = []\n",
        "        for rec in filtered_recommendations:\n",
        "            if \"Title:\" in rec:\n",
        "                try:\n",
        "                    title_part = rec.split(\"Title:\")[1].split(\",\")[0].strip()\n",
        "                    formatted_recommendations.append(f\"- {title_part}\")\n",
        "                except:\n",
        "                    formatted_recommendations.append(f\"- {rec.strip()}\")\n",
        "            elif rec.strip():\n",
        "                 formatted_recommendations.append(f\"- {rec.strip()}\")\n",
        "\n",
        "        limited_formatted_recommendations = formatted_recommendations[:5]\n",
        "\n",
        "        if limited_formatted_recommendations:\n",
        "            final_response = \"\\n\".join(limited_formatted_recommendations)\n",
        "        else:\n",
        "            final_response = \"Sorry, I couldn't find any movies of that genre in my list.\"\n",
        "\n",
        "        print(f\"\\nMovieRecs Assistant:\\n{final_response}\")\n",
        "else:\n",
        "    print(\"DataFrame 'df' was not loaded due to the file error. Exiting.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}